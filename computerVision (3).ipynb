{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# covering:\n",
        "### vision datasets\n",
        "### architecture of CNN\n",
        "### end to end multiclass image classification problem\n",
        "###Modeling CNN"
      ],
      "metadata": {
        "id": "EPPDmFF_2RvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### what are inputs&outputs\n",
        "- input-> image(batch size, height, width, color channels), then convert to numbers\n",
        "- output-> numberic outputs, converted to classification/labelled output"
      ],
      "metadata": {
        "id": "ITzcX42q2sDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### what are CNN(convolutional neural network)\n",
        "-  type of deep learning neural network designed to process and analyze structured grid data, such as images, audio, and time-series signals\n",
        "\n",
        "hyperparameters:\n",
        "1. input image\n",
        "2. input layer\n",
        "3. convolution layer\n",
        "4. hidden activation/non-linear activation\n",
        "5. pooling layer\n",
        "6. output layer\n",
        "7. output activation"
      ],
      "metadata": {
        "id": "ztB3RY-h3pv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###computer vision libraries\n",
        "- torchvision\n",
        "- torchvision.datasets\n",
        "- torchvision.models-> get pretrained computer vision models that you can leveragre for your own problem\n",
        "- torchvision.transforms-> functions for manipulating vision data(images) to be suitable for use with ml models\n",
        "- torch.utils.data.Dataset- create your own dataset with custom data\n",
        "- torch.utils.data.Dataloader-> creates python iterable over dataset\n"
      ],
      "metadata": {
        "id": "cROnOR605QvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as8AVo5j1GzC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- dataset that will be used is FashionMNIST from torchvision.Datasets"
      ],
      "metadata": {
        "id": "kLSE3QLK61wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get dataset\n",
        "train_data=datasets.FashionMNIST(\n",
        "    root=\"data\",#where to download data to\n",
        "    train=True,#train version of dataset, if false then will get test\n",
        "    download=True,\n",
        "    transform=ToTensor(),#how to transform data\n",
        "    target_transform=None #how to transform labels\n",
        ")\n",
        "\n",
        "test_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "YHLLsr2Y6qnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image,label=train_data[0]\n",
        "image,label"
      ],
      "metadata": {
        "id": "HzHG1a867w5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes"
      ],
      "metadata": {
        "id": "0gghgqpY8M7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_to_idx"
      ],
      "metadata": {
        "id": "HqcP_1hI8T-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape\n",
        "#color channels, height, width\n",
        "#1 color channel-> gray scale"
      ],
      "metadata": {
        "id": "zpOIEJfx8bd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize\n",
        "plt.imshow(image.squeeze(),cmap=\"gray\")\n",
        "plt.title(train_data.classes[label])\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "qKfN9wPC8nqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear or nonlinear??\n"
      ],
      "metadata": {
        "id": "E4kHXC899hEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare data, turn data into batches(mini-batches)\n"
      ],
      "metadata": {
        "id": "xmk9X0yq9SYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "why turn to batches?\n",
        "- more computationally efficient\n",
        "- give neural network more chances to update its gradient per epoch(update every mini-batch rather than after all data)\n",
        "- Any model trained by backpropagation or stochastic gradient descent (SGD) benefits from batching"
      ],
      "metadata": {
        "id": "mjK8UctA92oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#divide to batches\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE=32\n",
        "train_dataloader=DataLoader(train_data,batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader=DataLoader(test_data,batch_size=BATCH_SIZE, shuffle=False)#only for efficiency\n",
        "\n"
      ],
      "metadata": {
        "id": "3j8WtAqHGXR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show one batch\n",
        "train_features,train_labels=next(iter(train_dataloader))\n",
        "train_features.shape,train_labels.shape"
      ],
      "metadata": {
        "id": "RRulh0JAIWyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(42)\n",
        "random_idx=torch.randint(0,len(train_features), size=[1]).item()\n",
        "img,label=train_features[random_idx], train_labels[random_idx]\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.title(train_data.classes[label])\n",
        "plt.axis(False)\n"
      ],
      "metadata": {
        "id": "pJPF2viOHpxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### start with baseline mode\n",
        "model you will try and improve upon with subsequent models/experiments"
      ],
      "metadata": {
        "id": "cBjk3ewQJ7Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create flatten layer\n",
        "flatten_model=nn.Flatten()\n",
        "\n",
        "#single sample\n",
        "x=train_features[0]\n",
        "\n",
        "#flatten sample\n",
        "output=flatten_model(x)\n",
        "print(f\"shape before flatten: {x.shape}\")\n",
        "print(f\"shape after flatten: {output.shape}\")\n",
        "#instead of data being color channels, height, width -> color channels, height*width\n",
        "#condence infor into a single vector space"
      ],
      "metadata": {
        "id": "cUMryp1-Jsdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "why? we want to build a base line linear layer; it can handle single layer as vector not multilayers\n"
      ],
      "metadata": {
        "id": "cbKgQPvDLTZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class fashion_model0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.layer_stack=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "EBWU0ze1K7d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###equivalent code but manual(instead of using sequential):\n",
        "\n",
        "\n",
        "    \n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layer_1 = nn.Linear(in_features=input_shape, out_features=hidden_units)\n",
        "        self.layer_2 = nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.layer_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Kj0B4f4RMdE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "super().__init__()-> registering layers (so model.parameters() can find them)\n",
        "\n",
        "enabling saving/loading weights\n",
        "\n",
        "handling .to(device) correctly\n",
        "\n",
        "managing training/eval modes with .train() and .eval()"
      ],
      "metadata": {
        "id": "u3STkrMZL_zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0=fashion_model0(\n",
        "    input_shape=784,#28*28\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data.classes)\n",
        ").to(\"cpu\")\n",
        "model_0"
      ],
      "metadata": {
        "id": "4x7n7zZtNDGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "start_dim=1, end_dim=-1-> Keep dimension 0 (the batch), and flatten everything from dimension 1 to the last one"
      ],
      "metadata": {
        "id": "Y8mKdkeHNrHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "-G8jBb2zNvg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "eC1zS_UEOPz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchmetrics (run once in Colab)\n",
        "!pip install torchmetrics\n",
        "\n",
        "# Import the metric\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "\n",
        "# Create the accuracy function for 10 classes\n",
        "acc_fn = MulticlassAccuracy(num_classes=10)\n"
      ],
      "metadata": {
        "id": "C3__nGDEPZih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to time experiments- how fast it runs"
      ],
      "metadata": {
        "id": "ks4FgRy-PuLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time\n"
      ],
      "metadata": {
        "id": "BhmodjuUQJft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### steps for training loop\n",
        "1. loop through epoch\n",
        "2. loop through training batch\n",
        "3. loop through testing batches\n",
        "4. time"
      ],
      "metadata": {
        "id": "PVrGWbIGQqRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train loop\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_start=timer()\n",
        "epoch=3\n",
        "\n",
        "for epoch in tqdm(range(epoch)):\n",
        "  print(f\"epoch: {epoch}\\n---------\")\n",
        "  train_loss=0\n",
        "\n",
        "  for batch,(X,y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    #forward pass\n",
        "    y_pred=model_0(X)\n",
        "    #calculate loss\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "  if batch%400==0:\n",
        "    print(f\"loss at batch {batch}: {loss.item()}\")\n",
        "train_end=timer()\n",
        "train_loss/=len(train_dataloader)\n",
        "\n",
        "test_loss,test_acc=0,0\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  for X_test,y_test in test_dataloader:\n",
        "    test_pred=model_0(X_test)\n",
        "    test_loss+=loss_fn(test_pred,y_test)\n",
        "    test_acc+=acc_fn(test_pred.argmax(dim=1),y_test)\n",
        "  test_loss/=len(test_dataloader)\n",
        "  test_acc/=len(test_dataloader)\n",
        "print(f\"train loss: {train_loss} | test loss: {test_loss} | test acc:{test_acc}\")\n",
        "\n",
        "\n",
        "\n",
        "print_train_time(train_start,train_end)"
      ],
      "metadata": {
        "id": "SmVK95L9QXqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               accuracy:torch.nn.Module):\n",
        "  loss,acc=0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      y_pred=model(X)\n",
        "      loss+=loss_fn(y_pred,y)\n",
        "      acc+=accuracy(y_pred.argmax(dim=1),y)\n",
        "    loss/=len(data_loader)\n",
        "    acc/=len(data_loader)\n",
        "  return {\"model_name\":model.__class__.__name__,\n",
        "          \"model_loss\":loss.item(),\n",
        "          \"model_acc\":acc.item()}\n",
        "\n",
        "model_0_results=eval_model(model=model_0,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy=(acc_fn*100))\n",
        "model_0_results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N8AwulllUpOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating model with nonlinear function"
      ],
      "metadata": {
        "id": "iPsAajmYkUo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class fashion_model1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.layer_stack=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "       # nn.ReLU()\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "Sh1oHsFNW409"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_1=fashion_model1(input_shape=784,\n",
        "                       hidden_units=10,\n",
        "                       output_shape=len(train_data.classes))\n",
        "next(model_1.parameters())"
      ],
      "metadata": {
        "id": "Oi94vIeHlDmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "zL7VIA3kluW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating function for eval/test loop\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               acc_fn: torch.nn.Module):\n",
        "  train_loss,train_acc=0,0\n",
        "  model.train()\n",
        "  for batch,(X,y) in enumerate(train_dataloader):\n",
        "    #forward pass\n",
        "    y_pred=model(X)\n",
        "    #calculate loss\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss\n",
        "    train_acc+=acc_fn(y_pred.argmax(dim=1),y)\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss/=len(train_dataloader)\n",
        "    train_acc/=len(train_dataloader)\n",
        "  return {\"train_loss\":train_loss.item(),\n",
        "          \"train_acc\":train_acc.item()*100}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2SiDELw_mxDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              test_dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn:torch.nn.Module,\n",
        "              acc_fn: torch.nn.Module):\n",
        "  test_loss,test_acc=0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test,y_test in test_dataloader:\n",
        "      test_pred=model(X_test)\n",
        "      test_loss+=loss_fn(test_pred,y_test)\n",
        "      test_acc+=acc_fn(test_pred.argmax(dim=1),y_test)\n",
        "    test_loss/=len(test_dataloader)\n",
        "    test_acc/=len(test_dataloader)\n",
        "  print(f\"test loss: {test_loss} | test acc:{test_acc*100}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3265zkdJoNg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "epochs=3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_step(model=model_1,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             acc_fn=acc_fn)\n",
        "\n",
        "  test_step(model=model_1,\n",
        "            test_dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            acc_fn=acc_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "K5uH2RIgl6JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results\n"
      ],
      "metadata": {
        "id": "gN0fHVsEqctM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results=eval_model(model=model_1,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy=acc_fn)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "aDsHbHSrtCpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#build cnn-> known for finding patterns in visual data\n",
        "Instead of connecting every pixel to every neuron (like in a fully connected layer), it uses small filters (kernels) that slide across the image to detect features"
      ],
      "metadata": {
        "id": "YDr_pnIytmve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FasionCnn(nn.Module):\n",
        "  #TinyVGG-version\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,#dimensions of the sliding window over the input\n",
        "                  stride=1,#indicates how many pixels the kernel should be shifted over at a time\n",
        "                  padding=1),#Padding conserves data at the borders of activation maps\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,#calculated\n",
        "                  out_features=output_shape)\n",
        "        )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x=self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x=self.classifier(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#keep stride same as kernal size(default)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KNDRoHro4iJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2=FasionCnn(input_shape=1,#1 due to 1 color channel\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)\n",
        "                  )\n",
        "model_2\n"
      ],
      "metadata": {
        "id": "LK46VTDa9I2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set loss and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "TaTtse6NLPvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs=3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_step(model=model_2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             acc_fn=acc_fn)\n",
        "  test_step(model=model_2,\n",
        "            test_dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            acc_fn=acc_fn)\n"
      ],
      "metadata": {
        "id": "_EQUFyicLYcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,#calculated\n",
        "                  out_features=output_shape)\n",
        "        )\n",
        "- to calculate in_features you must multiply hidden_units with a value.\n",
        "to get this value pass a sample image through forward method, final height and width after sample was passed to all conv layers then multiply them to hidden_units"
      ],
      "metadata": {
        "id": "hIEEsCaNKzPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing layers individually to understand what their parameters does/controls"
      ],
      "metadata": {
        "id": "Slf68kNPGKwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test values in conv layer\n",
        "\n",
        "test_image=train_features[0].unsqueeze(dim=0)\n",
        "test_image.shape\n",
        "conv_layer=nn.Conv2d(in_channels=1,\n",
        "                     out_channels=10,\n",
        "                     kernel_size=3,\n",
        "                     stride=1,\n",
        "                     padding=1)\n",
        "conv_output=conv_layer(test_image)\n",
        "conv_output.shape"
      ],
      "metadata": {
        "id": "VyM4i8Ht-wNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.maxpool2d\n",
        "max_pool_layer=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "max_pool_output=max_pool_layer(conv_output)\n",
        "max_pool_output.shape"
      ],
      "metadata": {
        "id": "eC44cJrmGRA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxPool: slides a window(kernal_size*stride) across each feature map and takes the maximum value from each region compresses data(reduces dimensionality), keeping important features preserved.\n",
        "- Reduces spatial size → fewer parameters, faster computation\n",
        "\n",
        "- Keeps strongest signals → retains important features\n",
        "\n",
        "- Adds some translation invariance → small shifts in image don’t change output much"
      ],
      "metadata": {
        "id": "1u-zIsvaHVlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results=eval_model(model=model_2,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy=acc_fn)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "MuQljaJEIdUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compare results of 3 models\n",
        "import pandas as pd\n",
        "compare=pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare"
      ],
      "metadata": {
        "id": "yARjvaxIHVmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaulation metrics can be through:\n",
        "- makeing predictions through test sample\n",
        "- plotting\n",
        "- confusion matrix"
      ],
      "metadata": {
        "id": "QkWUOFjKKi6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extra notes"
      ],
      "metadata": {
        "id": "AkCko89DSYPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What benchmarking does (torch.backends.cudnn.benchmark)\n",
        "\n",
        "When benchmark=True, PyTorch asks cuDNN to try several algorithms, measure their speed, and pick the fastest one for your specific input shape.\n",
        "\n",
        "That picked algorithm is cached and reused for the same input sizes later.\n",
        "\n",
        "This makes training faster, but introduces a subtle issue:\n",
        "\n",
        "Because of benchmarking noise or hardware variation, the “fastest” algorithm may differ between runs — so your results may vary slightly each time.\n",
        "\n",
        "That means it’s not deterministic (you lose perfect reproducibility)."
      ],
      "metadata": {
        "id": "f2CDTwPbSaxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deterministic algorithms:\n",
        "A deterministic algorithm always gives the same output for the same input\n",
        "\n",
        "A non-deterministic algorithm can produce slightly different outputs even with the same inputs\n",
        "\n",
        "torch.use_deterministic_algorithms(True) is a PyTorch setting that forces all operations in your code to use deterministic (reproducible) algorithms — or raise an error if no deterministic version exists."
      ],
      "metadata": {
        "id": "lesIjjN3TMX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimization Algorithms:\n",
        "- Adadelta\n",
        "Implements Adadelta algorithm.\n",
        "\n",
        "- Adafactor\n",
        "Implements Adafactor algorithm.\n",
        "\n",
        "- Adagrad\n",
        "Implements Adagrad algorithm.\n",
        "\n",
        "- Adam\n",
        " Implements Adam algorithm.\n",
        "\n",
        "- AdamW\n",
        "Implements AdamW algorithm, where weight decay does not accumulate in the momentum nor variance.\n",
        "\n",
        "- SparseAdam\n",
        "\n",
        "SparseAdam implements a masked version of the Adam algorithm suitable for sparse gradients.\n",
        "\n",
        "- Adamax\n",
        "\n",
        "Implements Adamax algorithm (a variant of Adam based on infinity norm).\n",
        "\n",
        "- ASGD\n",
        "\n",
        "Implements Averaged Stochastic Gradient Descent.\n",
        "\n",
        "- LBFGS\n",
        "\n",
        "Implements L-BFGS algorithm.\n",
        "\n",
        "- Muon\n",
        "\n",
        "Implements Muon algorithm.\n",
        "\n",
        "- NAdam\n",
        "\n",
        "Implements NAdam algorithm.\n",
        "\n",
        "- RAdam\n",
        "\n",
        "Implements RAdam algorithm.\n",
        "\n",
        "- RMSprop\n",
        "\n",
        "Implements RMSprop algorithm.\n",
        "\n",
        "- Rprop\n",
        "\n",
        "Implements the resilient backpropagation algorithm.\n",
        "\n",
        "- SGD\n",
        "\n",
        "Implements stochastic gradient descent (optionally with momentum).\n",
        "\n",
        "\n",
        "Has fused?-> means if all operations are done on the same kernel or not:\n",
        "All steps are done inside one fused kernel->Faster, more efficient GPU use\n",
        "false-> Slower, more GPU overhead\n"
      ],
      "metadata": {
        "id": "U4vWOJbtUA5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lVACWnORUcnw"
      }
    }
  ]
}